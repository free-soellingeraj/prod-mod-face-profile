{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core\n",
    "> Defines the methods required for productionizing the face profile.  Must include Deployment class (for ubiops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import sys; import os\n",
    "from pathlib import Path\n",
    "import io\n",
    "import json\n",
    "import skimage\n",
    "from skimage import color\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from prcvd.img.core import (\n",
    "    TrainedSegmentationModel, MaskedImg\n",
    ")\n",
    "from prcvd.img.face import (\n",
    "    FacialProfile\n",
    ")\n",
    "from prcvd.core import json_to_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the location of the deployment package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depdir = Path(os.getcwd()).parent / 'deployment_package'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write `requirements.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dontest\n",
    "import pandas as pd\n",
    "REQUIREMENTS = [\n",
    "    # ['io', ''], \n",
    "    ['scikit-image', '=='+skimage.__version__]\n",
    "]\n",
    "reqfp = depdir / 'requirements.txt'\n",
    "pd.DataFrame(\n",
    "    [\n",
    "        {'r': req[0]+req[1]} for req in REQUIREMENTS\n",
    "    ]).to_csv(\n",
    "    reqfp, index=False, header=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write `Deployment` class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the `<prod library>.core` module\n",
    "This module will be imported into the deployment package so that this process can be repeatable, and tied to my jupyter notebook code.  Below, we will define and test the code just like any other notebook. Then at the end, we will push that exact code to the UbiOps endpoint.  Then, in the future, the process can be repeated if the endpoint needs to be updated.  Test in jupyter, then push."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Deployment:\n",
    "    def __init__(self, base_directory:str, context):\n",
    "        \"\"\"\n",
    "        Initialisation method for the deployment. It can for example be used for loading modules that have to be kept in\n",
    "        memory or setting up connections. Load your external model files (such as pickles or .h5 files) here.\n",
    "        :param str base_directory: absolute path to the directory where the deployment.py file is located\n",
    "        :param dict context: a dictionary containing details of the deployment that might be useful in your code.\n",
    "            It contains the following keys:\n",
    "                - deployment (str): name of the deployment\n",
    "                - version (str): name of the version\n",
    "                - input_type (str): deployment input type, either 'structured' or 'plain'\n",
    "                - output_type (str): deployment output type, either 'structured' or 'plain'\n",
    "                - language (str): programming language the deployment is running\n",
    "                - environment_variables (str): the custom environment variables configured for the deployment.\n",
    "                    You can also access those as normal environment variables via os.environ\n",
    "        \"\"\"\n",
    "        # global get_y_fn\n",
    "        # get_y_fn = lambda x: print('prod')\n",
    "        print(\"Loading face segmentation model.\")\n",
    "        print('base_directory', base_directory)\n",
    "        print('context', context)\n",
    "        self.basedir = Path(base_directory)\n",
    "        self.mod_fp = self.basedir/'model1.pkl'\n",
    "        # self.mod_fp = self.basedir/'model1'\n",
    "        self.output_classes = [\n",
    "            'Background/undefined', 'Lips', 'Eyes', 'Nose', 'Hair', \n",
    "            'Ears', 'Eyebrows', 'Teeth', 'General face', 'Facial hair',\n",
    "            'Specs/sunglasses'\n",
    "        ]\n",
    "        OUTPUT_SPEC_FP = Path(self.basedir)/'ubiops_output_spec.json'\n",
    "        with open(OUTPUT_SPEC_FP) as f:\n",
    "            self.output_spec = json.load(f)\n",
    "        self.output_mapping = {obj['name']: obj['id'] for obj in self.output_spec}\n",
    "        self.size = 224\n",
    "        \n",
    "        self.model = TrainedSegmentationModel(\n",
    "            mod_fp=self.mod_fp, \n",
    "            input_size=self.size,\n",
    "            output_classes=self.output_classes\n",
    "        )\n",
    "\n",
    "    \n",
    "    def request(self, data, attempt=1):\n",
    "        \"\"\"\n",
    "        Method for deployment requests, called separately for each individual request.\n",
    "        :param dict/str data: request input data. In case of deployments with structured data, a Python dictionary\n",
    "            with as keys the input fields as defined upon deployment creation via the platform. In case of a deployment\n",
    "            with plain input, it is a string.\n",
    "                - img: list, data from image\n",
    "                - sampling_strategy: str, 'use_all' | ...\n",
    "                - align_face: bool, yes/no apply face alignment\n",
    "                - num_attempts: int, max attempts before failure (sometimes face alignment fails)\n",
    "                \n",
    "        :return dict/str: request output. In case of deployments with structured output data, a Python dictionary\n",
    "            with as keys the output fields as defined upon deployment creation via the platform. In case of a deployment\n",
    "            with plain output, it is a string. In this example, a dictionary with the key: output.\n",
    "        \"\"\"\n",
    "        img = MaskedImg()\n",
    "        img.load_from_file(data['img'])\n",
    "        \n",
    "        try:\n",
    "            profile = FacialProfile(\n",
    "                model=self.model, \n",
    "                img=img, \n",
    "                sampling_strategy=data['sampling_strategy'], \n",
    "                align_face=data['align_face']\n",
    "            )\n",
    "            \n",
    "        except:\n",
    "            if not attempt > data['num_attempts']:\n",
    "                return self.request(\n",
    "                    data=data,\n",
    "                    attempt=attempt+1,\n",
    "                )\n",
    "            else:\n",
    "                return None, None\n",
    "\n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.imshow(profile.segmask.decoded_img.img)\n",
    "        plt.imshow(\n",
    "            skimage.color.label2rgb(np.array(profile.segmask.mask)), \n",
    "            alpha=0.3\n",
    "        )\n",
    "        plt.title('Computed fWHR based on Segmentation Only (not FaceMesh).\\nfWHR: {}'.format(profile.fwhr))\n",
    "        plt.scatter(x=[profile.bizygomatic_right[0]], \n",
    "                    y=[profile.bizygomatic_right[1]], \n",
    "                    marker='+', c='orange')\n",
    "        plt.scatter(x=[profile.bizygomatic_left[0]], \n",
    "                    y=[profile.bizygomatic_left[1]], \n",
    "                    marker='+', c='orange')\n",
    "        plt.plot(\n",
    "            [profile.bizygomatic_right[0], profile.bizygomatic_right[0]], \n",
    "            [0, profile.segmask.mask.shape[1]-1],'ro-')\n",
    "        plt.plot(\n",
    "            [profile.bizygomatic_left[0], profile.bizygomatic_left[0]], \n",
    "            [0, profile.segmask.mask.shape[1]-1],'ro-')\n",
    "\n",
    "        plt.scatter(x=[profile.upperfacial_top[0]], \n",
    "                    y=[profile.upperfacial_top[1]],\n",
    "                    marker='+', c='red')\n",
    "        plt.plot(\n",
    "            [0, profile.segmask.mask.shape[0]-1], \n",
    "            [profile.upperfacial_top[1], profile.upperfacial_top[1]],\n",
    "            'go-'\n",
    "        )\n",
    "\n",
    "        plt.scatter(x=[profile.upperfacial_bottom[0]], \n",
    "                    y=[profile.upperfacial_bottom[1]],\n",
    "                    marker='+', c='red')\n",
    "        plt.plot(\n",
    "            [0, profile.segmask.mask.shape[0]-1], \n",
    "            [profile.upperfacial_bottom[1], profile.upperfacial_bottom[1]], 'go-')\n",
    "        \n",
    "        outfp = self.basedir / 'tmp.jpeg'\n",
    "        plt.savefig(outfp, format='jpeg')\n",
    "        outimg = MaskedImg()\n",
    "        outimg.load_from_file(fn=outfp)\n",
    "        \n",
    "        row = profile.get_profile()\n",
    "        row['model_id'] = str(self.mod_fp) # for ubiops output type str\n",
    "        row = {**row, **{'img': str(outfp)}}\n",
    "        \n",
    "        return {self.output_mapping[k]: v for k,v in row.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading face segmentation model.\n",
      "base_directory /home/fortville/code/prod-mod-face-profile/deployment_package\n",
      "context {}\n"
     ]
    }
   ],
   "source": [
    "d = Deployment(\n",
    "    base_directory=depdir,\n",
    "    context={}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dontest\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dontest\n",
    "imgs = Path('/data1/data/skin-tone/from_zenodo/Media/MediaForExport/')\n",
    "ls = [fp for fp in list(imgs.ls()) if str(fp)[-4:] == '.jpg']\n",
    "img = MaskedImg()\n",
    "img.load_from_file(fn=ls[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dontest\n",
    "data = {\n",
    "    # 'img': np.array(img.img),\n",
    "    'img': ls[2],\n",
    "    'sampling_strategy': 'use_all',\n",
    "    'align_face': True,\n",
    "    'num_attempts': 10\n",
    "}\n",
    "out = d.request(data=data,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0000': (52, 47, 49),\n",
       " '0001': (133, 86, 112),\n",
       " '0002': (179, 144, 159),\n",
       " '0003': (33, 28, 34),\n",
       " '0004': (106, 10, 34),\n",
       " '0005': (118, 102, 117),\n",
       " '0006': None,\n",
       " '0007': (144, 122, 132),\n",
       " '0008': None,\n",
       " '0009': None,\n",
       " '0010': (97, 87, 107),\n",
       " '0011': (76, 72, 92),\n",
       " '0012': (196, 163, 176),\n",
       " '0013': (145, 122, 133),\n",
       " '0014': (188, 157, 166),\n",
       " '0015': 3.4990597042834075,\n",
       " '0016': 6,\n",
       " '0017': -0.0,\n",
       " '0018': 1.596774193548387,\n",
       " '0019': 99.0,\n",
       " '0020': 62.0,\n",
       " '0021': 18828,\n",
       " '0022': 0.018748672190354792,\n",
       " '0023': 0.04110898661567878,\n",
       " '0024': 0.30359039728064585,\n",
       " '0025': 0.0014871468026343743,\n",
       " '0026': 0.013702995538559592,\n",
       " '0027': 0.0,\n",
       " '0028': 0.2953579774803484,\n",
       " '0029': 0.0,\n",
       " '0030': 0.0,\n",
       " '0031': 0.006107924367962609,\n",
       " '0032': 0.0053112385808370514,\n",
       " '0033': 0.06161036753770979,\n",
       " '0034': 0.09693010410027618,\n",
       " '0035': 0.15604418950499258,\n",
       " '0036': '/home/fortville/code/prod-mod-face-profile/deployment_package/model1.pkl',\n",
       " '0037': '/home/fortville/code/prod-mod-face-profile/deployment_package/tmp.jpeg'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dontest\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plan\n",
    "1. fastest would be to make individual outputs, specified by a json instruction\n",
    "2. image should be a blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 2020-10-12-Training a Face Segmentation Model for Automatic Skin Tone Detection.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#dontest\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Everything here down should go into github actions\n",
    "Upgrades:\n",
    "1. Put the model file in the cloud (s3).\n",
    "    1. simplified cli, ?versioned?\n",
    "    2. ?pachyderm?\n",
    "2. Add a command to add the model to the deployment_package as before it gets zipped up and shipped off\n",
    "3. Longer term, need to bring the model training into this notebook?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package up this library and ship it in `depdir/libraries/`\n",
    "Need to find an example of one of these libraries that you can bundle up and make our library look like that, then copy it into the libraries directory for shipping.\n",
    "\n",
    "The UbiOps docs around what actually goes in the libraries directory is pretty unclear.  I will just try some stuff and ask Anouk if I have trouble.\n",
    "\n",
    "My first attempt will be to package up the entire directory, delete the deployment package itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dontest\n",
    "!cp -r .. ../../prod-mod-face-profile-cp\n",
    "!rm -rf ../../prod-mod-face-profile-cp/deployment_package/\n",
    "!rm -rf ../../prod-mod-face-profile-cp/*.zip\n",
    "!rm -rf ../deployment_package/libraries\n",
    "!mkdir ../deployment_package/libraries\n",
    "!mv ../../prod-mod-face-profile-cp ../deployment_package/libraries/prod-mod-face-profile\n",
    "!rm -rf ../deployment_package/libraries/prod-mod-face-profile/.git/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding `prcvd` (proprietary code) to `deployment_package/libraries`\n",
    "Need to add `prcvd` to libraries because it's private for now.\n",
    "Instead of using the local copy, we will clone prcvd into our project directory here and use that one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'prcvd'...\n",
      "remote: Enumerating objects: 682, done.\u001b[K\n",
      "remote: Counting objects: 100% (682/682), done.\u001b[K\n",
      "remote: Compressing objects: 100% (374/374), done.\u001b[K\n",
      "remote: Total 682 (delta 406), reused 562 (delta 292), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (682/682), 1.19 MiB | 5.96 MiB/s, done.\n",
      "Resolving deltas: 100% (406/406), done.\n",
      "Branch 'dev' set up to track remote branch 'dev' from 'origin'.\n",
      "Switched to a new branch 'dev'\n"
     ]
    }
   ],
   "source": [
    "#dontest\n",
    "# requires username and password\n",
    "gh_fp = Path(os.getcwd()).parent.parent/'.secrets/github.json'\n",
    "gh = json_to_dict(fp=gh_fp)\n",
    "user = gh['username']\n",
    "pw = gh['password']\n",
    "branch = 'dev'\n",
    "\n",
    "!rm -rf ../deployment_package/libraries/prcvd\n",
    "!cd ../deployment_package/libraries && git clone https://{user}:{pw}@github.com/prcvd/prcvd.git\n",
    "!cd ../deployment_package/libraries/prcvd && git checkout {branch}\n",
    "!rm -rf ../deployment_package/libraries/prcvd/.git/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dontest\n",
    "!cp ../ubiops_output_spec.json ../deployment_package/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182M\t../deployment_package\n"
     ]
    }
   ],
   "source": [
    "#dontest\n",
    "!du -sh ../deployment_package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dontest\n",
    "## Set up deployment\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "import ubiops\n",
    "\n",
    "SECRETS_FP = Path(os.getenv('HOME'))/'code/.secrets/ubiops.json'\n",
    "OUTPUT_SPEC_FP = Path(os.getcwd()).parent/'ubiops_output_spec.json'\n",
    "INPUT_SPEC_FP = Path(os.getcwd()).parent/'ubiops_input_spec.json'\n",
    "\n",
    "with open(SECRETS_FP) as f:\n",
    "    secrets = json.load(f)\n",
    "\n",
    "with open(OUTPUT_SPEC_FP) as f:\n",
    "    output_spec = json.load(f)\n",
    "    \n",
    "with open(INPUT_SPEC_FP) as f:\n",
    "    input_spec = json.load(f)\n",
    "    \n",
    "    \n",
    "API_TOKEN = secrets['API_TOKEN']\n",
    "PROJECT_NAME = \"facial-profile\"\n",
    "\n",
    "DEPLOYMENT_NAME = 'endtoend-3'\n",
    "DEPLOYMENT_VERSION = 'v1'\n",
    "\n",
    "client = ubiops.ApiClient(\n",
    "    ubiops.Configuration(\n",
    "        api_key={'Authorization': API_TOKEN}, \n",
    "        host='https://api.ubiops.com/v2.1')\n",
    ")\n",
    "api = ubiops.CoreApi(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.68 s, sys: 276 ms, total: 7.96 s\n",
      "Wall time: 8.64 s\n"
     ]
    }
   ],
   "source": [
    "#dontest\n",
    "shutil.make_archive(\n",
    "    base_name=Path(os.getcwd()).parent/'deployment_package', \n",
    "    format='zip', \n",
    "    root_dir=Path(os.getcwd()).parent,\n",
    "    base_dir='deployment_package'\n",
    ")\n",
    "zipfp = Path(os.getcwd()).parent / 'deployment_package.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-26-69fae40ff582>\", line 34, in <module>\n",
      "    data=deployment_template\n",
      "  File \"/home/fortville/.local/lib/python3.6/site-packages/ubiops/api/core_api.py\", line 3747, in deployments_create\n",
      "    return self.deployments_create_with_http_info(project_name, data, **kwargs)  # noqa: E501\n",
      "  File \"/home/fortville/.local/lib/python3.6/site-packages/ubiops/api/core_api.py\", line 3844, in deployments_create_with_http_info\n",
      "    collection_formats=collection_formats)\n",
      "  File \"/home/fortville/.local/lib/python3.6/site-packages/ubiops/api_client.py\", line 361, in call_api\n",
      "    _preload_content, _request_timeout, _host)\n",
      "  File \"/home/fortville/.local/lib/python3.6/site-packages/ubiops/api_client.py\", line 190, in __call_api\n",
      "    _request_timeout=_request_timeout)\n",
      "  File \"/home/fortville/.local/lib/python3.6/site-packages/ubiops/api_client.py\", line 405, in request\n",
      "    body=body)\n",
      "  File \"/home/fortville/.local/lib/python3.6/site-packages/ubiops/rest.py\", line 276, in POST\n",
      "    body=body)\n",
      "  File \"/home/fortville/.local/lib/python3.6/site-packages/ubiops/rest.py\", line 229, in request\n",
      "    raise ApiException(http_resp=r)\n",
      "ubiops.exceptions.ApiException: (400)\n",
      "Reason: Bad Request\n",
      "HTTP response headers: HTTPHeaderDict({'server': 'ubiops', 'date': 'Sat, 20 Feb 2021 22:33:40 GMT', 'content-type': 'application/json', 'content-length': '68', 'allow': 'GET, POST, HEAD, OPTIONS', 'x-frame-options': 'DENY', 'vary': 'Origin', 'x-content-type-options': 'nosniff', 'Via': '1.1 google', 'Alt-Svc': 'clear'})\n",
      "HTTP response body: {\"error\":\"Deployment with given name already exists in the project\"}\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-26-69fae40ff582>\", line 59, in <module>\n",
      "    data=version_template\n",
      "  File \"/home/fortville/.local/lib/python3.6/site-packages/ubiops/api/core_api.py\", line 14360, in versions_create\n",
      "    return self.versions_create_with_http_info(project_name, deployment_name, data, **kwargs)  # noqa: E501\n",
      "  File \"/home/fortville/.local/lib/python3.6/site-packages/ubiops/api/core_api.py\", line 14468, in versions_create_with_http_info\n",
      "    collection_formats=collection_formats)\n",
      "  File \"/home/fortville/.local/lib/python3.6/site-packages/ubiops/api_client.py\", line 361, in call_api\n",
      "    _preload_content, _request_timeout, _host)\n",
      "  File \"/home/fortville/.local/lib/python3.6/site-packages/ubiops/api_client.py\", line 190, in __call_api\n",
      "    _request_timeout=_request_timeout)\n",
      "  File \"/home/fortville/.local/lib/python3.6/site-packages/ubiops/api_client.py\", line 405, in request\n",
      "    body=body)\n",
      "  File \"/home/fortville/.local/lib/python3.6/site-packages/ubiops/rest.py\", line 276, in POST\n",
      "    body=body)\n",
      "  File \"/home/fortville/.local/lib/python3.6/site-packages/ubiops/rest.py\", line 229, in request\n",
      "    raise ApiException(http_resp=r)\n",
      "ubiops.exceptions.ApiException: (400)\n",
      "Reason: Bad Request\n",
      "HTTP response headers: HTTPHeaderDict({'server': 'ubiops', 'date': 'Sat, 20 Feb 2021 22:33:40 GMT', 'content-type': 'application/json', 'content-length': '69', 'allow': 'GET, POST, HEAD, OPTIONS', 'x-frame-options': 'DENY', 'vary': 'Origin', 'x-content-type-options': 'nosniff', 'Via': '1.1 google', 'Alt-Svc': 'clear'})\n",
      "HTTP response body: {\"error\":\"Version with given name already exists for the deployment\"}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading facial-profile, endtoend-3 v2\n",
      "Cleaning up.\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "#dontest\n",
    "## TODO\n",
    "import traceback\n",
    "from prcvd.serving.core import depv_increment\n",
    "import configparser\n",
    "\n",
    "settings = configparser.ConfigParser()\n",
    "settings.read(Path(os.getcwd()).parent/'settings.ini')\n",
    "\n",
    "deployment_template = ubiops.DeploymentCreate(\n",
    "    name=DEPLOYMENT_NAME,\n",
    "    description=settings['DEFAULT']['description'],\n",
    "    input_type='structured',\n",
    "    output_type='structured',\n",
    "    input_fields=[\n",
    "        ubiops.DeploymentInputFieldCreate(\n",
    "            name=str(obj['name']),\n",
    "            data_type=obj['data_type']['value'])\n",
    "        for obj in input_spec\n",
    "    ],\n",
    "    output_fields=[\n",
    "        ubiops.DeploymentOutputFieldCreate(\n",
    "            name=str(obj['id']),\n",
    "            data_type=obj['data_type']['value'])\n",
    "        for obj in output_spec\n",
    "    ],\n",
    "    labels={'demo': 'mod'}\n",
    ")\n",
    "\n",
    "try:\n",
    "    api.deployments_create(\n",
    "        project_name=PROJECT_NAME,\n",
    "        data=deployment_template\n",
    "    )\n",
    "    \n",
    "except:\n",
    "    traceback.print_exc()\n",
    "    api.deployments_update(\n",
    "        deployment_name=DEPLOYMENT_NAME,\n",
    "        project_name=PROJECT_NAME,\n",
    "        data=deployment_template\n",
    "    )\n",
    "\n",
    "# Create the version\n",
    "while True:\n",
    "    try:\n",
    "        version_template = ubiops.VersionCreate(\n",
    "            version=DEPLOYMENT_VERSION,\n",
    "            language='python3.6',\n",
    "            memory_allocation=3000,\n",
    "            minimum_instances=0,\n",
    "            maximum_instances=1,\n",
    "            maximum_idle_time=1800 # = 30 minutes\n",
    "        )\n",
    "        api.versions_create(\n",
    "            project_name=PROJECT_NAME,\n",
    "            deployment_name=DEPLOYMENT_NAME,\n",
    "            data=version_template\n",
    "        )\n",
    "        break\n",
    "        \n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "        # file_upload_result =api.revisions_file_upload(\n",
    "        #     project_name=PROJECT_NAME,\n",
    "        #     deployment_name=DEPLOYMENT_NAME,\n",
    "        #     version=DEPLOYMENT_VERSION,\n",
    "        #     file=zipfp\n",
    "        # )\n",
    "        DEPLOYMENT_VERSION = depv_increment(\n",
    "                v=DEPLOYMENT_VERSION\n",
    "        )\n",
    "\n",
    "# Upload the zipped deployment package\n",
    "print('Uploading {}, {} {}'.format(\n",
    "    PROJECT_NAME, DEPLOYMENT_NAME, DEPLOYMENT_VERSION)\n",
    ")\n",
    "file_upload_result =api.revisions_file_upload(\n",
    "    project_name=PROJECT_NAME,\n",
    "    deployment_name=DEPLOYMENT_NAME,\n",
    "    version=DEPLOYMENT_VERSION,\n",
    "    file=zipfp\n",
    ")\n",
    "print('Cleaning up.')\n",
    "# TODO: delete the zip.  If successful, save the zip to s3 then delete it.\n",
    "# check that the build is successful.\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment Notes\n",
    "With slight tweaking, the notebook from ubiops cookbooks was made repeatable.  The flow it follows is:\n",
    "1. Write the `Deployment` class in the notebook, and export it to the package created by nbdev\n",
    "2. Update the code in deployment package using the scripts.  In the future, it would be cool to have the scripts under control like the notebooks are with nbdev. Maybe an expansion of nbdev?  Basically, just hash the `deployment_package` folder and run updates if the hash changes.  Maybe use DVC?\n",
    "3. Deploy new version. Versions increment by 1 every time.  \n",
    "### Manual steps with the Deployment\n",
    "1. I am cleaning up failed deployments (TODO: figure out how to automate that task.)\n",
    "2. I am checking to confirm deployment success/failure (TODO: anouk to \n",
    "\n",
    "\n",
    "### Issues with the Deployment\n",
    "1. Don't know how to replace a version instead of create a new one.  Seems to be a limit of 5 versions.  There seems to be a bug where I am able to add versions but not see them in the interface (Called a \"revision\")\n",
    "2. `libraries/` doesn't really work as advertised because the libraries I put in there (each having setup.py in the root) are not being installed prior to execution of `deployment.py`.  \n",
    "3. Second issue related to installing private depenencies is that the `mod` project, which contains the `Deployment` class requires `prcvd` but if `mod` is installed first, it doesn't know where to look for `prcvd`. I am attempting to remove the named dependency from `mod/settings.ini`\n",
    "4. The function to register a new version takes just under 5 minutes to complete.  I am not sure what it's doing for all that time because I am not getting any messages.  It would be better if I saw some output from that cell while it was executing.  Even better would be if it didn't require so much time.  I mean, it should be done as soon as the data is uploaded.  Maybe it takes 4.5 minutes to upload 230mb?  (Follow up: I wonder if I can deploy multiple endpoint versions at the same time?)\n",
    "5. torch is huge ~800MB so I had to increase the mem size on the endpoint to 3000mb.  That resolved it.  The traceback on that was not not super helpful.\n",
    "6.`ImportError: libGL.so.1: cannot open shared object file: No such file or directory`:\n",
    "    1. solution: add ubiops.yaml to do `apt` pulls\n",
    "    2. use `opencv-python-headless`\n",
    "7. Build phase failure resulting from function missing from the `__main__` context running the ubiops driver (the one running `from deployment import Deployment`). During training of the model, I used a custom defined label function called `get_y_fn` that defined the filename mapping from base files to their corresponding label files.  That function was saved with the rest of the model artifacts (weights, params, transforms). When my code went to load the trained model, it required `get_y_fn` to be defined in the `__main__` context, however I did not have access to this context.  After trying many work-arounds, it became clear that I needed to surgically remove `get_y_fn`, a process that is documented at the [fastai forum](https://forums.fast.ai/t/need-access-to-main-to-load-model/85948/2?u=asoellinger).  This is an ongoing issue because during the surgery, the model became about 10x slower to execute the `learner.predict(img)`.\n",
    "8. I changed the inputs (added 3 additional ones) and needed to create a new deployment to get those new inputs to be registered.  So maybe inputs are not updated on new versions? (could be a bug on ubiops)\n",
    "9. The procedure around the blob could be made more clear.  I found it a little bit of a different workflow, and just took some trial and error to make it work.\n",
    "#### Retrospective - after the deployment worked\n",
    "9. Should the `Deployment` class methods be made general for all models? How?\n",
    "10. How to run the deployment from github actions?  Trigger on changes to `prcvd`?\n",
    "\n",
    "### Opinions from the Deployment Phase\n",
    "1. I don't like the logging viewer.  Use the black command line viz like is common in many apps like this.  e.g. github Actions\n",
    "2. Add keyboard interrupt to deployment script.  I can't shut this thing down once it's started.  Could be a ipynb notebook issue.\n",
    "3. In Logging, I lose breadcrumbs.\n",
    "4. UbiOps should track the number of failed deployments as a company metric.  Like \"# of deployments needed to get one that worked\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
